{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb7a6ea-ab9f-4582-ac27-e5eec9fc7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp import read_trees, tree_level\n",
    "from utils import Statistics, merge_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ac22ef-f780-4afb-9fea-0c892ec5ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_trees = read_trees(\"/efs/dengcai/dp/out/gold\")\n",
    "tot = len(gold_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41c708a-d77f-49da-b51d-a305b39a5595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.43 0.52\n",
      "63.88 0.56\n",
      "89.66 0.11\n",
      "91.76 0.10\n",
      "59.08 0.65\n",
      "65.83 0.44\n",
      "89.62 0.13\n",
      "91.81 0.09\n"
     ]
    }
   ],
   "source": [
    "# Table 1: compute the mean and standard deviation.\n",
    "array = []\n",
    "for old in '123 456 789 555 666'.split():\n",
    "    old_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "    pred_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "    stats_l, stats_u = tree_level(gold_trees, old_trees, pred_trees, scheme='both')\n",
    "    stat = merge_statistics(stats_l)\n",
    "    lcm, las = stat[\"whole\"].new_acc, stat[\"word\"].new_acc\n",
    "    stat = merge_statistics(stats_u)\n",
    "    ucm, uas = stat[\"whole\"].new_acc, stat[\"word\"].new_acc\n",
    "    array.append([lcm, ucm, las, uas])\n",
    "import numpy as np\n",
    "data = np.array(array)\n",
    "for avg, std in zip(data.mean(0), data.std(0)):\n",
    "    print (f\"{avg*100:.2f} {std*100:.2f}\")\n",
    "\n",
    "array = []\n",
    "for old in '123 456 789 555 666'.split():\n",
    "    old_trees = read_trees(f\"/efs/dengcai/dp/out/stackptr{old}.pred\")\n",
    "    pred_trees = read_trees(f\"/efs/dengcai/dp/out/stackptr{old}.pred\")\n",
    "    stats_l, stats_u = tree_level(gold_trees, old_trees, pred_trees, scheme='both')\n",
    "    stat = merge_statistics(stats_l)\n",
    "    lcm, las = stat[\"whole\"].new_acc, stat[\"word\"].new_acc\n",
    "    stat = merge_statistics(stats_u)\n",
    "    ucm, uas = stat[\"whole\"].new_acc, stat[\"word\"].new_acc\n",
    "    array.append([lcm, ucm, las, uas])\n",
    "import numpy as np\n",
    "data = np.array(array)\n",
    "for avg, std in zip(data.mean(0), data.std(0)):\n",
    "    print (f\"{avg*100:.2f} {std*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682a1bd-c609-4bf5-965c-cf9ca50b468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 6: compute the upper-bounds of BCR \n",
    "for NUM in [10]:\n",
    "    for dropout in [0.15, 0.2, 0.25]:\n",
    "        all_nfi_stats = []\n",
    "        all_acc_stats = []\n",
    "        for old in \"123 456 789 555 666\".split():\n",
    "            for new in \"1 2 3 4 5\".split():\n",
    "                print (f\"{old}->{new}\")\n",
    "                effective_nfi_stats = []\n",
    "                effective_acc_stats = []\n",
    "                old_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "\n",
    "                pred_trees, pred_scores = [], []\n",
    "                for sample_seed in range(1, NUM+1):\n",
    "                    pred_trees = pred_trees + read_trees(f\"/efs/dengcai/dp/out/deepbiaf{new}.dropout{dropout}sample{sample_seed}.pred\")\n",
    "\n",
    "                for i in range(tot):\n",
    "                    gold_trees_i = [ gold_trees[i] for t in range(NUM) ]\n",
    "                    old_trees_i = [ old_trees[i] for t in range(NUM) ]\n",
    "                    pred_trees_i = pred_trees[i::tot]\n",
    "\n",
    "                    stats = tree_level(gold_trees_i, old_trees_i, pred_trees_i)\n",
    "                    idx = list(range(NUM))\n",
    "                    idx.sort(key=lambda x:stats[x][\"word\"].nfr if \"word\" in stats[x].keys else 1000000 )\n",
    "                    picked = idx[0]\n",
    "                    effective_nfi_stats.append(stats[picked])\n",
    "                    idx = list(range(NUM))\n",
    "                    idx.sort(key=lambda x:-stats[x][\"word\"].new_acc if \"word\" in stats[x].keys else 1000000)\n",
    "                    picked = idx[0]\n",
    "                    effective_acc_stats.append(stats[picked])\n",
    "                stat = merge_statistics(effective_nfi_stats)\n",
    "                all_nfi_stats.append(stat)\n",
    "                stat = merge_statistics(effective_acc_stats)\n",
    "                all_acc_stats.append(stat)\n",
    "        print (dropout)\n",
    "        print (\"nfr\")\n",
    "        stat = merge_statistics(all_nfi_stats)\n",
    "        stat.report([\"whole\", \"word\"])\n",
    "        print (\"acc\")\n",
    "        stat = merge_statistics(all_acc_stats)\n",
    "        stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "for NUM in [10]:\n",
    "    for dropout in [0.15, 0.2, 0.25]:\n",
    "        all_nfi_stats = []\n",
    "        all_acc_stats = []\n",
    "        for old in \"123 456 789 555 666\".split():\n",
    "            for new in \"1 2 3 4 5\".split():\n",
    "                print (f\"{old}->{new}\")\n",
    "                effective_nfi_stats = []\n",
    "                effective_acc_stats = []\n",
    "                old_trees = read_trees(f\"/efs/dengcai/dp/out/stackptr{old}.pred\")\n",
    "\n",
    "                pred_trees, pred_scores = [], []\n",
    "                for sample_seed in range(1, NUM+1):\n",
    "                    pred_trees = pred_trees + read_trees(f\"/efs/dengcai/dp/out/stackptr{new}.dropout{dropout}sample{sample_seed}.pred\")\n",
    "\n",
    "                for i in range(tot):\n",
    "                    gold_trees_i = [ gold_trees[i] for t in range(NUM) ]\n",
    "                    old_trees_i = [ old_trees[i] for t in range(NUM) ]\n",
    "                    pred_trees_i = pred_trees[i::tot]\n",
    "\n",
    "                    stats = tree_level(gold_trees_i, old_trees_i, pred_trees_i)\n",
    "                    idx = list(range(NUM))\n",
    "                    idx.sort(key=lambda x:stats[x][\"word\"].nfr if \"word\" in stats[x].keys else 1000000 )\n",
    "                    picked = idx[0]\n",
    "                    effective_nfi_stats.append(stats[picked])\n",
    "                    idx = list(range(NUM))\n",
    "                    idx.sort(key=lambda x:-stats[x][\"word\"].new_acc if \"word\" in stats[x].keys else 1000000)\n",
    "                    picked = idx[0]\n",
    "                    effective_acc_stats.append(stats[picked])\n",
    "                stat = merge_statistics(effective_nfi_stats)\n",
    "                all_nfi_stats.append(stat)\n",
    "                stat = merge_statistics(effective_acc_stats)\n",
    "                all_acc_stats.append(stat)\n",
    "        print (dropout)\n",
    "        print (\"nfr\")\n",
    "        stat = merge_statistics(all_nfi_stats)\n",
    "        stat.report([\"whole\", \"word\"])\n",
    "        print (\"acc\")\n",
    "        stat = merge_statistics(all_acc_stats)\n",
    "        stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "for NUM in [10]:\n",
    "    for dropout in [0.15, 0.2, 0.25]:\n",
    "        all_nfi_stats = []\n",
    "        all_acc_stats = []\n",
    "        for old in \"123 456 789 555 666\".split():\n",
    "            for new in \"1 2 3 4 5\".split():\n",
    "                print (f\"{old}->{new}\")\n",
    "                effective_nfi_stats = []\n",
    "                effective_acc_stats = []\n",
    "                old_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "\n",
    "                pred_trees, pred_scores = [], []\n",
    "                for sample_seed in range(1, NUM+1):\n",
    "                    pred_trees = pred_trees + read_trees(f\"/efs/dengcai/dp/out/stackptr{new}.dropout{dropout}sample{sample_seed}.pred\")\n",
    "\n",
    "                for i in range(tot):\n",
    "                    gold_trees_i = [ gold_trees[i] for t in range(NUM) ]\n",
    "                    old_trees_i = [ old_trees[i] for t in range(NUM) ]\n",
    "                    pred_trees_i = pred_trees[i::tot]\n",
    "\n",
    "                    stats = tree_level(gold_trees_i, old_trees_i, pred_trees_i)\n",
    "                    idx = list(range(NUM))\n",
    "                    idx.sort(key=lambda x:stats[x][\"word\"].nfr if \"word\" in stats[x].keys else 1000000 )\n",
    "                    picked = idx[0]\n",
    "                    effective_nfi_stats.append(stats[picked])\n",
    "                    idx = list(range(NUM))\n",
    "                    idx.sort(key=lambda x:-stats[x][\"word\"].new_acc if \"word\" in stats[x].keys else 1000000)\n",
    "                    picked = idx[0]\n",
    "                    effective_acc_stats.append(stats[picked])\n",
    "                stat = merge_statistics(effective_nfi_stats)\n",
    "                all_nfi_stats.append(stat)\n",
    "                stat = merge_statistics(effective_acc_stats)\n",
    "                all_acc_stats.append(stat)\n",
    "        print (dropout)\n",
    "        print (\"nfr\")\n",
    "        stat = merge_statistics(all_nfi_stats)\n",
    "        stat.report([\"whole\", \"word\"])\n",
    "        print (\"acc\")\n",
    "        stat = merge_statistics(all_acc_stats)\n",
    "        stat.report([\"whole\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9e109-e030-4f81-8366-32c47c0cc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5: BCR (beam search)\n",
    "def read_scores(fname):\n",
    "    return [ float(x.strip()) for x in open(fname).readlines()]\n",
    "\n",
    "for beam in [10]:\n",
    "    all_stats = []\n",
    "    for old in \"123 456 789 555 666\".split():\n",
    "        for new in \"1 2 3 4 5\".split():\n",
    "            print (f\"{old}=>{new} {beam}\")\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{new}.bs{beam}.pred\")\n",
    "            pred_scores = read_scores(f\"/efs/dengcai/dp/out/deepbiaf{new}.bs{beam}.deepbiaf{old}.score\")\n",
    "            assert len(pred_trees) == len(pred_scores), (len(pred_trees), len(pred_scores))\n",
    "            final_pred_trees = []\n",
    "            for i in range(tot):\n",
    "                pred_trees_i = pred_trees[i*beam:i*beam+beam]\n",
    "                pred_scores_i = pred_scores[i*beam:i*beam+beam]\n",
    "                idx = list(range(beam))\n",
    "                idx.sort(key=lambda x:pred_scores_i[x])\n",
    "                picked = idx[0]\n",
    "                final_pred_trees.append(pred_trees_i[picked])\n",
    "            stats = tree_level(gold_trees, old_trees, final_pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])\n",
    "\n",
    "for beam in [10]:\n",
    "    all_stats = []\n",
    "    for old in \"123 456 789 555 666\".split():\n",
    "        for new in \"1 2 3 4 5\".split():\n",
    "            print (f\"{old}=>{new} {beam}\")\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/stackptr{old}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/stackptr{new}.bs{beam}.pred\")\n",
    "            pred_scores = read_scores(f\"/efs/dengcai/dp/out/stackptr{new}.bs{beam}.stackptr{old}.score\")\n",
    "            assert len(pred_trees) == len(pred_scores), (len(pred_trees), len(pred_scores))\n",
    "            final_pred_trees = []\n",
    "            for i in range(tot):\n",
    "                pred_trees_i = pred_trees[i*beam:i*beam+beam]\n",
    "                pred_scores_i = pred_scores[i*beam:i*beam+beam]\n",
    "                idx = list(range(beam))\n",
    "                idx.sort(key=lambda x:pred_scores_i[x])\n",
    "                picked = idx[0]\n",
    "                final_pred_trees.append(pred_trees_i[picked])\n",
    "            stats = tree_level(gold_trees, old_trees, final_pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])\n",
    "\n",
    "for beam in [10]:\n",
    "    all_stats = []\n",
    "    for old in \"123 456 789 555 666\".split():\n",
    "        for new in \"1 2 3 4 5\".split():\n",
    "            print (f\"{old}=>{new} {beam}\")\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/stackptr{new}.bs{beam}.pred\")\n",
    "            pred_scores = read_scores(f\"/efs/dengcai/dp/out/stackptr{new}.bs{beam}.deepbiaf{old}.score\")\n",
    "            assert len(pred_trees) == len(pred_scores), (len(pred_trees), len(pred_scores))\n",
    "            final_pred_trees = []\n",
    "            for i in range(tot):\n",
    "                pred_trees_i = pred_trees[i*beam:i*beam+beam]\n",
    "                pred_scores_i = pred_scores[i*beam:i*beam+beam]\n",
    "                idx = list(range(beam))\n",
    "                idx.sort(key=lambda x:pred_scores_i[x])\n",
    "                picked = idx[0]\n",
    "                final_pred_trees.append(pred_trees_i[picked])\n",
    "            stats = tree_level(gold_trees, old_trees, final_pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfe0f97-1214-4886-a09a-23d3fe2610bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123->1\n",
      "123->2\n",
      "123->3\n",
      "123->4\n",
      "123->5\n",
      "456->1\n",
      "456->2\n",
      "456->3\n",
      "456->4\n",
      "456->5\n",
      "789->1\n",
      "789->2\n",
      "789->3\n",
      "789->4\n",
      "789->5\n",
      "555->1\n",
      "555->2\n",
      "555->3\n",
      "555->4\n",
      "555->5\n",
      "666->1\n",
      "666->2\n",
      "666->3\n",
      "666->4\n",
      "666->5\n",
      "0.15\n",
      "word\n",
      "NFR: 1.11% NFI: 13.87% new Acc: 92.01% PFR: 1.36% old Acc: 91.76% count: 547450\n",
      "whole\n",
      "NFR: 1.20% NFI: 3.60% new Acc: 66.76% PFR: 4.08% old Acc: 63.88% count: 51925\n",
      "123->1\n",
      "123->2\n",
      "123->3\n",
      "123->4\n",
      "123->5\n",
      "456->1\n",
      "456->2\n",
      "456->3\n",
      "456->4\n",
      "456->5\n",
      "789->1\n",
      "789->2\n",
      "789->3\n",
      "789->4\n",
      "789->5\n",
      "555->1\n",
      "555->2\n",
      "555->3\n",
      "555->4\n",
      "555->5\n",
      "666->1\n",
      "666->2\n",
      "666->3\n",
      "666->4\n",
      "666->5\n",
      "0.15\n",
      "word\n",
      "NFR: 0.84% NFI: 10.30% new Acc: 91.88% PFR: 0.91% old Acc: 91.81% count: 547450\n",
      "whole\n",
      "NFR: 1.05% NFI: 3.12% new Acc: 66.45% PFR: 1.67% old Acc: 65.83% count: 51925\n",
      "123->1\n",
      "123->2\n",
      "123->3\n",
      "123->4\n",
      "123->5\n",
      "456->1\n",
      "456->2\n",
      "456->3\n",
      "456->4\n",
      "456->5\n",
      "789->1\n",
      "789->2\n",
      "789->3\n",
      "789->4\n",
      "789->5\n",
      "555->1\n",
      "555->2\n",
      "555->3\n",
      "555->4\n",
      "555->5\n",
      "666->1\n",
      "666->2\n",
      "666->3\n",
      "666->4\n",
      "666->5\n",
      "0.15\n",
      "word\n",
      "NFR: 0.84% NFI: 10.21% new Acc: 91.78% PFR: 0.86% old Acc: 91.76% count: 547450\n",
      "whole\n",
      "NFR: 1.12% NFI: 3.14% new Acc: 64.36% PFR: 1.60% old Acc: 63.88% count: 51925\n"
     ]
    }
   ],
   "source": [
    "# Table 3 & 5 : BCR (dropout-p sampling)\n",
    "def read_scores(fname):\n",
    "    return [ float(x.strip()) for x in open(fname).readlines()]\n",
    "for NUM in [10]:\n",
    "    for dropout in [0.15]:\n",
    "        all_stats = []\n",
    "        for old in \"123 456 789 555 666\".split():\n",
    "            for new in \"1 2 3 4 5\".split():\n",
    "                print (f\"{old}->{new}\")\n",
    "                old_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "\n",
    "                pred_trees, pred_scores = [], []\n",
    "                for sample_seed in range(1, NUM+1):\n",
    "                    pred_trees = pred_trees + read_trees(f\"/efs/dengcai/dp/out/stackptr{new}.dropout{dropout}sample{sample_seed}.pred\")\n",
    "                    pred_scores = pred_scores + read_scores(f\"/efs/dengcai/dp/out/stackptr{new}.dropout{dropout}sample{sample_seed}.deepbiaf{old}.score\")\n",
    "                assert len(pred_trees) == len(pred_scores), (len(pred_trees), len(pred_scores))\n",
    "                final_pred_trees = []\n",
    "                for i in range(tot):\n",
    "                    pred_trees_i = pred_trees[i::tot]\n",
    "                    pred_scores_i = pred_scores[i::tot]\n",
    "                    idx = list(range(NUM))\n",
    "                    assert len(idx) == len(pred_trees_i) == len(pred_scores_i)\n",
    "                    idx.sort(key=lambda x:pred_scores_i[x])\n",
    "                    picked = idx[0]\n",
    "                    final_pred_trees.append(pred_trees_i[picked])\n",
    "                stats = tree_level(gold_trees, old_trees, final_pred_trees)\n",
    "                stat = merge_statistics(stats)\n",
    "                all_stats.append(stat)\n",
    "        print (dropout)\n",
    "        stat = merge_statistics(all_stats)\n",
    "        stat.report([\"whole\", \"word\"])\n",
    "\n",
    "for NUM in [10]:\n",
    "    for dropout in [0.15]:\n",
    "        all_stats = []\n",
    "        for old in \"123 456 789 555 666\".split():\n",
    "            for new in \"1 2 3 4 5\".split():\n",
    "                print (f\"{old}->{new}\")\n",
    "                old_trees = read_trees(f\"/efs/dengcai/dp/out/stackptr{old}.pred\")\n",
    "\n",
    "                pred_trees, pred_scores = [], []\n",
    "                for sample_seed in range(1, NUM+1):\n",
    "                    pred_trees = pred_trees + read_trees(f\"/efs/dengcai/dp/out/stackptr{new}.dropout{dropout}sample{sample_seed}.pred\")\n",
    "                    pred_scores = pred_scores + read_scores(f\"/efs/dengcai/dp/out/stackptr{new}.dropout{dropout}sample{sample_seed}.stackptr{old}.score\")\n",
    "                assert len(pred_trees) == len(pred_scores), (len(pred_trees), len(pred_scores))\n",
    "                final_pred_trees = []\n",
    "                for i in range(tot):\n",
    "                    pred_trees_i = pred_trees[i::tot]\n",
    "                    pred_scores_i = pred_scores[i::tot]\n",
    "                    idx = list(range(NUM))\n",
    "                    assert len(idx) == len(pred_trees_i) == len(pred_scores_i)\n",
    "                    idx.sort(key=lambda x:pred_scores_i[x])\n",
    "                    picked = idx[0]\n",
    "                    final_pred_trees.append(pred_trees_i[picked])\n",
    "                stats = tree_level(gold_trees, old_trees, final_pred_trees)\n",
    "                stat = merge_statistics(stats)\n",
    "                all_stats.append(stat)\n",
    "        print (dropout)\n",
    "        stat = merge_statistics(all_stats)\n",
    "        stat.report([\"whole\", \"word\"])\n",
    "\n",
    "for NUM in [10]:\n",
    "    for dropout in [0.15]:\n",
    "        all_stats = []\n",
    "        for old in \"123 456 789 555 666\".split():\n",
    "            for new in \"1 2 3 4 5\".split():\n",
    "                print (f\"{old}->{new}\")\n",
    "                old_trees = read_trees(f\"/efs/dengcai/dp/out/deepbiaf{old}.pred\")\n",
    "\n",
    "                pred_trees, pred_scores = [], []\n",
    "                for sample_seed in range(1, NUM+1):\n",
    "                    pred_trees = pred_trees + read_trees(f\"/efs/dengcai/dp/out/deepbiaf{new}.dropout{dropout}sample{sample_seed}.pred\")\n",
    "                    pred_scores = pred_scores + read_scores(f\"/efs/dengcai/dp/out/deepbiaf{new}.dropout{dropout}sample{sample_seed}.deepbiaf{old}.score\")\n",
    "                assert len(pred_trees) == len(pred_scores), (len(pred_trees), len(pred_scores))\n",
    "                final_pred_trees = []\n",
    "                for i in range(tot):\n",
    "                    pred_trees_i = pred_trees[i::tot]\n",
    "                    pred_scores_i = pred_scores[i::tot]\n",
    "                    idx = list(range(NUM))\n",
    "                    assert len(idx) == len(pred_trees_i) == len(pred_scores_i)\n",
    "                    idx.sort(key=lambda x:pred_scores_i[x])\n",
    "                    picked = idx[0]\n",
    "                    final_pred_trees.append(pred_trees_i[picked])\n",
    "                stats = tree_level(gold_trees, old_trees, final_pred_trees)\n",
    "                stat = merge_statistics(stats)\n",
    "                all_stats.append(stat)\n",
    "        print (dropout)\n",
    "        stat = merge_statistics(all_stats)\n",
    "        stat.report([\"whole\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bdfed0-aa9f-48e6-8cb1-e0d70ccaccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3: distillation\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"deepbiaf\"\n",
    "all_stats = []\n",
    "for seed in \"123 456 789 555 666\".split():\n",
    "    pred_trees = read_trees(f\"/efs/dengcai/dp/out/gkd.{m2}.{m1}{seed}.1.pred\")\n",
    "    old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{seed}.pred\")\n",
    "    stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "    stat = merge_statistics(stats)\n",
    "    all_stats.append(stat)\n",
    "stat = merge_statistics(all_stats)\n",
    "stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "m1 = \"stackptr\"\n",
    "m2 = \"stackptr\"\n",
    "all_stats = []\n",
    "for seed in \"123 456 789 555 666\".split():\n",
    "    pred_trees = read_trees(f\"/efs/dengcai/dp/out/gkd.{m2}.{m1}{seed}.1.pred\")\n",
    "    old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{seed}.pred\")\n",
    "    stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "    stat = merge_statistics(stats)\n",
    "    all_stats.append(stat)\n",
    "stat = merge_statistics(all_stats)\n",
    "stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"stackptr\"\n",
    "all_stats = []\n",
    "for seed in \"123 456 789 555 666\".split():\n",
    "    pred_trees = read_trees(f\"/efs/dengcai/dp/out/gkd.{m2}.{m1}{seed}.1.pred\")\n",
    "    old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{seed}.pred\")\n",
    "    stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "    stat = merge_statistics(stats)\n",
    "    all_stats.append(stat)\n",
    "stat = merge_statistics(all_stats)\n",
    "stat.report([\"whole\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf54cf3-0ff3-44a9-a4b9-1e4e58287e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3: untreated\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"deepbiaf\"\n",
    "all_stats = []\n",
    "for s1 in \"123 456 789 555 666\".split():\n",
    "    for s2 in \"1 2 3 4 5\".split():\n",
    "        old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{s1}.pred\")\n",
    "        pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{s2}.pred\")\n",
    "        stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "        stat = merge_statistics(stats)\n",
    "        all_stats.append(stat)\n",
    "stat = merge_statistics(all_stats)\n",
    "stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "m1 = \"stackptr\"\n",
    "m2 = \"stackptr\"\n",
    "all_stats = []\n",
    "for s1 in \"123 456 789 555 666\".split():\n",
    "    for s2 in \"1 2 3 4 5\".split():\n",
    "        old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{s1}.pred\")\n",
    "        pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{s2}.pred\")\n",
    "        stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "        stat = merge_statistics(stats)\n",
    "        all_stats.append(stat)\n",
    "stat = merge_statistics(all_stats)\n",
    "stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"stackptr\"\n",
    "all_stats = []\n",
    "for s1 in \"123 456 789 555 666\".split():\n",
    "    for s2 in \"1 2 3 4 5\".split():\n",
    "        old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{s1}.pred\")\n",
    "        pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{s2}.pred\")\n",
    "        stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "        stat = merge_statistics(stats)\n",
    "        all_stats.append(stat)\n",
    "stat = merge_statistics(all_stats)\n",
    "stat.report([\"whole\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65bef7-9def-4835-a39c-378304761029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 & Figure 3: ensemble\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"deepbiaf\"\n",
    "for ensemble_size in range(5, 6):\n",
    "    all_stats = []\n",
    "    for s1 in \"123 456 789 555 666\".split():\n",
    "        for s2 in \"A B C D E\".split():\n",
    "            s2 = f\"{ensemble_size}{s2}\"\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{s1}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{s2}.pred\")\n",
    "            stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    print(ensemble_size)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])\n",
    "\n",
    "m1 = \"stackptr\"\n",
    "m2 = \"stackptr\"\n",
    "for ensemble_size in range(5, 6):\n",
    "    all_stats = []\n",
    "    for s1 in \"123 456 789 555 666\".split():\n",
    "        for s2 in \"A B C D E\".split():\n",
    "            s2 = f\"{ensemble_size}{s2}\"\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{s1}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{s2}.pred\")\n",
    "            stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    print(ensemble_size)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])\n",
    "\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"stackptr\"\n",
    "for ensemble_size in range(5, 6):\n",
    "    all_stats = []\n",
    "    for s1 in \"123 456 789 555 666\".split():\n",
    "        for s2 in \"A B C D E\".split():\n",
    "            s2 = f\"{ensemble_size}{s2}\"\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{s1}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{s2}.pred\")\n",
    "            stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    print(ensemble_size)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09085a-f585-4773-ba28-c08c201585a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble => ensemble\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"deepbiaf\"\n",
    "for ensemble_size in range(2, 11):\n",
    "    all_stats = []\n",
    "    for s1 in \"A B C D E\".split():\n",
    "        for s2 in \"A B C D E\".split():\n",
    "            if s1 == s2:\n",
    "                continue\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{ensemble_size}{s1}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{ensemble_size}{s2}.pred\")\n",
    "            stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    print(ensemble_size)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "m1 = \"stackptr\"\n",
    "m2 = \"stackptr\"\n",
    "for ensemble_size in range(2, 11):\n",
    "    all_stats = []\n",
    "    for s1 in \"A B C D E\".split():\n",
    "        for s2 in \"A B C D E\".split():\n",
    "            if s1 == s2:\n",
    "                continue\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{ensemble_size}{s1}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{ensemble_size}{s2}.pred\")\n",
    "            stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    print(ensemble_size)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])\n",
    "\n",
    "\n",
    "m1 = \"deepbiaf\"\n",
    "m2 = \"stackptr\"\n",
    "for ensemble_size in range(2, 11):\n",
    "    all_stats = []\n",
    "    for s1 in \"A B C D E\".split():\n",
    "        for s2 in \"A B C D E\".split():\n",
    "            if s1 == s2:\n",
    "                continue\n",
    "            old_trees = read_trees(f\"/efs/dengcai/dp/out/{m1}{ensemble_size}{s1}.pred\")\n",
    "            pred_trees = read_trees(f\"/efs/dengcai/dp/out/{m2}{ensemble_size}{s2}.pred\")\n",
    "            stats = tree_level(gold_trees, old_trees, pred_trees)\n",
    "            stat = merge_statistics(stats)\n",
    "            all_stats.append(stat)\n",
    "    print(ensemble_size)\n",
    "    stat = merge_statistics(all_stats)\n",
    "    stat.report([\"whole\", \"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094e34a-95c7-4720-afaf-1ed09a0ecd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ce02a-8a8a-421e-ae46-8168829016bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c766a7-2f77-4a42-83af-48b71e4c8c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0c6fd-e5dd-427d-9a9c-9aeb2d2f0659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed7b7a-5426-4f60-9510-09cb72b2b317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1885ec2-0bbb-4c4b-9693-e6f30437f638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccbb85-655b-4cce-97c3-06afb3e5e4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb553d93-0efb-4270-8731-812e2327fca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6d090-6103-490a-a0b7-1143dd56f259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e94eae-a7c4-42e6-b5cb-656c7ced2aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779dac8-2325-43c7-8bc4-161e5efe7442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023dd74-4d30-4992-a15f-0ef4cd570bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf393c49-96b8-4ea9-873a-ab5fed11a4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07a2d2-1c9e-456a-89a2-f29a14cd01b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1beb71-2528-4490-82a8-09ec36d0d0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
